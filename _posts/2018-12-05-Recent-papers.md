---
title: "Neat papers in ML and DS: Dec 2018"
layout: post
date: 2018-11-08 11:35
tags: data science, history
---

- [ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness](https://arxiv.org/abs/1811.12231)
- [Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet](https://openreview.net/forum?id=SkfMWhAqYQ)

NeurIPS
- [Are GANs Created Equal? A Large-Scale Study](http://papers.nips.cc/paper/7350-are-gans-created-equal-a-large-scale-study)
- [An intriguing failing of convolutional neural networks and the CoordConv solution](http://papers.nips.cc/paper/8169-an-intriguing-failing-of-convolutional-neural-networks-and-the-coordconv-solution)
- [On the Dimensionality of Word Embedding](http://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding)
- [Adversarial Examples that Fool both Computer Vision and Time-Limited Humans](http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans)
- [Bias and Generalization in Deep Generative Models: An Empirical Study](http://papers.nips.cc/paper/8277-bias-and-generalization-in-deep-generative-models-an-empirical-study)
- [How Does Batch Normalization Help Optimization?](http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization)
- [Training Deep Models Faster with Robust, Approximate Importance Sampling](http://papers.nips.cc/paper/7957-training-deep-models-faster-with-robust-approximate-importance-sampling)
- [DropMax: Adaptive Variational Softmax](http://papers.nips.cc/paper/7371-dropmax-adaptive-variational-softmax)
- [Relational recurrent neural networks](http://papers.nips.cc/paper/7960-relational-recurrent-neural-networks)
- [Neural Arithmetic Logic Units](http://papers.nips.cc/paper/8027-neural-arithmetic-logic-units)
