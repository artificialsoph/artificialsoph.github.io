<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <generator uri="http://jekyllrb.com" version="3.8.5">Jekyll</generator>
  
  
  <link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" />
  <updated>2019-04-08T15:07:40+00:00</updated>
  <id>http://localhost:4000//</id>

  
    <title type="html">soph</title>
  

  
    <subtitle>Minimal, responsive Jekyll theme for hackers.</subtitle>
  

  
    <author>
        <name>Sophia Ray Searcy</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Neat papers in ML and DS: Dec 2018</title>
      
      
      <link href="http://localhost:4000/2018/11/08/Recent-papers/" rel="alternate" type="text/html" title="Neat papers in ML and DS: Dec 2018" />
      
      <published>2018-11-08T11:35:00+00:00</published>
      <updated>2018-11-08T11:35:00+00:00</updated>
      <id>http://localhost:4000/2018/11/08/Recent-papers</id>
      <content type="html" xml:base="http://localhost:4000/2018/11/08/Recent-papers/">&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1811.12231&quot;&gt;ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=SkfMWhAqYQ&quot;&gt;Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NeurIPS&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7350-are-gans-created-equal-a-large-scale-study&quot;&gt;Are GANs Created Equal? A Large-Scale Study&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/8169-an-intriguing-failing-of-convolutional-neural-networks-and-the-coordconv-solution&quot;&gt;An intriguing failing of convolutional neural networks and the CoordConv solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding&quot;&gt;On the Dimensionality of Word Embedding&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans&quot;&gt;Adversarial Examples that Fool both Computer Vision and Time-Limited Humans&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/8277-bias-and-generalization-in-deep-generative-models-an-empirical-study&quot;&gt;Bias and Generalization in Deep Generative Models: An Empirical Study&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization&quot;&gt;How Does Batch Normalization Help Optimization?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7957-training-deep-models-faster-with-robust-approximate-importance-sampling&quot;&gt;Training Deep Models Faster with Robust, Approximate Importance Sampling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7371-dropmax-adaptive-variational-softmax&quot;&gt;DropMax: Adaptive Variational Softmax&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7960-relational-recurrent-neural-networks&quot;&gt;Relational recurrent neural networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/8027-neural-arithmetic-logic-units&quot;&gt;Neural Arithmetic Logic Units&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="data" />
      
        <category term="science," />
      
        <category term="history" />
      

      
        <summary type="html">ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet NeurIPS Are GANs Created Equal? A Large-Scale Study An intriguing failing of convolutional neural networks and the CoordConv solution On the Dimensionality of Word Embedding Adversarial Examples that Fool both Computer Vision and Time-Limited Humans Bias and Generalization in Deep Generative Models: An Empirical Study How Does Batch Normalization Help Optimization? Training Deep Models Faster with Robust, Approximate Importance Sampling DropMax: Adaptive Variational Softmax Relational recurrent neural networks Neural Arithmetic Logic Units</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Performance of different model types on MNIST by year</title>
      
      
      <link href="http://localhost:4000/2018/11/08/mnist-history/" rel="alternate" type="text/html" title="Performance of different model types on MNIST by year" />
      
      <published>2018-11-08T11:35:00+00:00</published>
      <updated>2018-11-08T11:35:00+00:00</updated>
      <id>http://localhost:4000/2018/11/08/mnist-history</id>
      <content type="html" xml:base="http://localhost:4000/2018/11/08/mnist-history/">&lt;p&gt;Today I was trying to answer the question of why it seems like so much attention was given to support vector machines in the past. I had assumed that before the Deep Learning renaissance in 2006, SVMs were the dominate model because they outperformed Deep Learning models of the time. But if that was true, I wanted to see how it changed over time and how SVMs and DL models compared to less practical models like KNN.&lt;/p&gt;

&lt;p&gt;To investigate this, I went to a table of top performances on the MNIST dataset maintained by Yann LeCun. This table is helpfully organized by model type and year.&lt;/p&gt;

&lt;p&gt;I made a bunch of hand modifications (which you can find &lt;a href=&quot;images/mnist-history.csv&quot;&gt;here&lt;/a&gt;) to allow me to plot the performance of different model types. To my surprise, SVMs were actually never the dominant. The reasons SVMs were favored over Deep Learning turn out to be much more subtle and I’ll save them for later.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mnist-history.png&quot; /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="data" />
      
        <category term="science," />
      
        <category term="history" />
      

      
        <summary type="html">Today I was trying to answer the question of why it seems like so much attention was given to support vector machines in the past. I had assumed that before the Deep Learning renaissance in 2006, SVMs were the dominate model because they outperformed Deep Learning models of the time. But if that was true, I wanted to see how it changed over time and how SVMs and DL models compared to less practical models like KNN. To investigate this, I went to a table of top performances on the MNIST dataset maintained by Yann LeCun. This table is helpfully organized by model type and year. I made a bunch of hand modifications (which you can find here) to allow me to plot the performance of different model types. To my surprise, SVMs were actually never the dominant. The reasons SVMs were favored over Deep Learning turn out to be much more subtle and I’ll save them for later.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">How to clean Apple’s butterfly keys with a metrocard</title>
      
      
      <link href="http://localhost:4000/2018/09/21/butterfly-keys/" rel="alternate" type="text/html" title="How to clean Apple's butterfly keys with a metrocard" />
      
      <published>2018-09-21T18:46:00+00:00</published>
      <updated>2018-09-21T18:46:00+00:00</updated>
      <id>http://localhost:4000/2018/09/21/butterfly-keys</id>
      <content type="html" xml:base="http://localhost:4000/2018/09/21/butterfly-keys/">&lt;p&gt;In early 2015, Apple debuted their butterfly keyboard on their new “macbook”. Since then Apple has migrated this “feature” to their macbook pro line while several have &lt;a href=&quot;https://theoutline.com/post/2402/the-new-macbook-keyboard-is-ruining-my-life&quot;&gt;voiced loud complaints&lt;/a&gt; about the shallow, fragile keyboard. Apple has since &lt;a href=&quot;https://theoutline.com/post/5052/apple-admits-its-computers-are-broken&quot;&gt;admitted that there’s a problem&lt;/a&gt; and offered to repair keyboards with sticky or unresponsive keys.&lt;/p&gt;

&lt;p&gt;But turning your computer in for a repair is tedious and likely requires parting with your computer for a week or more. Also, perhaps you are like me and have already extensively repaired your  &lt;a href=&quot;https://www.ifixit.com/Teardown/Retina+MacBook+2015+Teardown/39841&quot;&gt;unrepairable&lt;/a&gt; computer and violated the warranty in a number of ways. In these cases, it might make more sense to repair your keyboard on your own.&lt;/p&gt;

&lt;p&gt;I’ve been using this dumb keyboard for 3.5 years now (what can I say, I love the romance of having the smallest possible computer that can do the things I need). I’ve cleaned these keys more times than I can count and I’ll document my process here. I know this process works for gen 1 and gen 2 of the butterfly keyboard and I’m guessing it works for the rest.&lt;/p&gt;

&lt;h1&gt;What you’ll need&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;A metrocard or similar flimsy card.&lt;/li&gt;
  &lt;li&gt;A q-tips/cloth/paper towel to clean out the keyhole.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Step 1: Remove the key cap and switch&lt;/h1&gt;

&lt;div class=&quot;img&quot;&gt;
    &lt;img src=&quot;https://www.dropbox.com/s/z72ku05ca1nbhfg/IMG_4826.jpg?dl=1&quot; alt=&quot;The back of the 'U' key cap and butterfly switch. I've marked the 4 points where the key cap connects to the switch. Sorry my potato phone stinks at macros!&quot; /&gt;
    &lt;small&gt;The back of the 'U' key cap and butterfly switch. I've marked the 4 points where the key cap connects to the switch. Sorry my potato phone stinks at macros!&lt;/small&gt;
&lt;/div&gt;

&lt;p&gt;Before you do anything, make sure you understand how the key cap and switch connect to each other. The &lt;strong&gt;key cap&lt;/strong&gt; is what I’m calling the black piece with the key printed on int. The &lt;strong&gt;switch&lt;/strong&gt; is what I’m calling the gray-white mechanism inside the keycap that flaps its wings like a butterfly.&lt;/p&gt;

&lt;p&gt;There are four points that connect the key cap and switch: two clips on the top and two hooks on the bottom.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When removing the key cap from the keyboard, it is very important that you only lift from the top, where the clips are. The hooks should only be disconnected after the clips have.&lt;/strong&gt; If you get this wrong, you can break the hooks on the bottom of the key cap or the pins on the bottom of the switch. Trust me, I’ve done this!&lt;/p&gt;

&lt;p&gt;Now, first thing you’ll do is insert one of the corners of your key cap removal tool (metrocard) under the &lt;strong&gt;top&lt;/strong&gt; of the key and pry it up. (video of this below) Sometimes you’ll get both the key cap and switch together, sometimes the key cap will come loose first. The switch is held in by four little pins on the inner rim and you can easily remove it with a fingernail or your key cap removal tool.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Q2TtO-ClJT0?rel=0&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1&gt;Step 2: Clean up your mess&lt;/h1&gt;

&lt;p&gt;Remove whatever it is you got under there. It can be really small! Take your time here. I’ve typically used a damp cloth to do this but I also have a high tolerance for risk so you do you.&lt;/p&gt;

&lt;h1&gt;Step 3: Replace the switch and key cap&lt;/h1&gt;

&lt;p&gt;For this step, a similar word of caution to step 1. &lt;strong&gt;It is very important that you don’t squish the hooks in the key cap onto the pins of the switch&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If you haven’t already, remove the switch from the key cap.&lt;/li&gt;
  &lt;li&gt;Insert the switch itself (so, not the key cap) into the key hole. The side of the switch that should face the computer bulges out a bit, while the top should be relatively flat. You’ll press down on the switch until the pins click into the plastic brace.&lt;/li&gt;
  &lt;li&gt;Start with the bottom of the key cap. Slide the hooks over the pins on the bottom of the switch and then lay the key cap on top of the switch.&lt;/li&gt;
  &lt;li&gt;You should be able to gently press on the key and hear the top two clips engage.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have a video of these steps below.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/hYiKWL7SZC4?rel=0&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="howto" />
      

      
        <summary type="html">In early 2015, Apple debuted their butterfly keyboard on their new “macbook”. Since then Apple has migrated this “feature” to their macbook pro line while several have voiced loud complaints about the shallow, fragile keyboard. Apple has since admitted that there’s a problem and offered to repair keyboards with sticky or unresponsive keys. But turning your computer in for a repair is tedious and likely requires parting with your computer for a week or more. Also, perhaps you are like me and have already extensively repaired your unrepairable computer and violated the warranty in a number of ways. In these cases, it might make more sense to repair your keyboard on your own. I’ve been using this dumb keyboard for 3.5 years now (what can I say, I love the romance of having the smallest possible computer that can do the things I need). I’ve cleaned these keys more times than I can count and I’ll document my process here. I know this process works for gen 1 and gen 2 of the butterfly keyboard and I’m guessing it works for the rest. What you’ll need A metrocard or similar flimsy card. A q-tips/cloth/paper towel to clean out the keyhole. Step 1: Remove the key cap and switch The back of the 'U' key cap and butterfly switch. I've marked the 4 points where the key cap connects to the switch. Sorry my potato phone stinks at macros! Before you do anything, make sure you understand how the key cap and switch connect to each other. The key cap is what I’m calling the black piece with the key printed on int. The switch is what I’m calling the gray-white mechanism inside the keycap that flaps its wings like a butterfly. There are four points that connect the key cap and switch: two clips on the top and two hooks on the bottom. When removing the key cap from the keyboard, it is very important that you only lift from the top, where the clips are. The hooks should only be disconnected after the clips have. If you get this wrong, you can break the hooks on the bottom of the key cap or the pins on the bottom of the switch. Trust me, I’ve done this! Now, first thing you’ll do is insert one of the corners of your key cap removal tool (metrocard) under the top of the key and pry it up. (video of this below) Sometimes you’ll get both the key cap and switch together, sometimes the key cap will come loose first. The switch is held in by four little pins on the inner rim and you can easily remove it with a fingernail or your key cap removal tool. Step 2: Clean up your mess Remove whatever it is you got under there. It can be really small! Take your time here. I’ve typically used a damp cloth to do this but I also have a high tolerance for risk so you do you. Step 3: Replace the switch and key cap For this step, a similar word of caution to step 1. It is very important that you don’t squish the hooks in the key cap onto the pins of the switch If you haven’t already, remove the switch from the key cap. Insert the switch itself (so, not the key cap) into the key hole. The side of the switch that should face the computer bulges out a bit, while the top should be relatively flat. You’ll press down on the switch until the pins click into the plastic brace. Start with the bottom of the key cap. Slide the hooks over the pins on the bottom of the switch and then lay the key cap on top of the switch. You should be able to gently press on the key and hear the top two clips engage. I have a video of these steps below.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Bootcamp Guide for Everyone Else</title>
      
      
      <link href="http://localhost:4000/2018/08/13/bootcamp-guide/" rel="alternate" type="text/html" title="Bootcamp Guide for Everyone Else" />
      
      <published>2018-08-13T10:21:00+00:00</published>
      <updated>2018-08-13T10:21:00+00:00</updated>
      <id>http://localhost:4000/2018/08/13/bootcamp-guide</id>
      <content type="html" xml:base="http://localhost:4000/2018/08/13/bootcamp-guide/">&lt;p&gt;&lt;em&gt;note 8/15: this is still a work in progress so check back as I fill it in&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I’ve been a bootcamp instructor at &lt;a href=&quot;https://www.thisismetis.com/&quot;&gt;Metis&lt;/a&gt; for about a year now&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. It’s been an incredible, rewarding experience and I plan to stick around for a while. In that time, I’ve been asked a lot about bootcamps. People want to know how bootcamps work, if bootcamps are right for them, holy cow are they really $15,000? I’m putting this guide together to answer those questions.&lt;/p&gt;

&lt;p&gt;This guide is for anyone interested in moving to a technical career, like coding, data science, or similar and are able to participate in an immersive (roughly 3 months of full time work) bootcamp. I especially intend this for people who aren’t already familiar with the tech/coding world and who don’t have ~$15,000 laying around to drop on a bootcamp.&lt;/p&gt;

&lt;p&gt;My TLDR:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bootcamps are for real. They can be a legitimately great way to start a good career that too few people have access to.&lt;/li&gt;
  &lt;li&gt;First, make sure joining an bootcamp is right for you.
    &lt;ul&gt;
      &lt;li&gt;Are you likely to finish and likely to be fully committed to the job search after finishing? Be very honest with yourself about this.&lt;/li&gt;
      &lt;li&gt;A great way to figure this out is to complete a &lt;a href=&quot;https://www.coursereport.com/blog/coding-bootcamp-prep-programs-the-ultimate-guide&quot;&gt;bootcamp prep program&lt;/a&gt; (many are free). Bootcamp prep is also a great way to figure out which type of bootcamp (like coding vs data science) is right for you.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Don’t put too much pressure on getting in and plan to get rejected from your first bootcamp. Bootcamps can be selective and admissions necessarily involves chance. You’ll learn each time you interview. You might have a favorite bootcamp but there are many good ones. Most bootcamps allow you to interview again later if you are rejected.&lt;/li&gt;
  &lt;li&gt;Don’t let cost be an issue.
    &lt;ul&gt;
      &lt;li&gt;Any decent bootcamp will work with you on payment if you are admitted. They’ll walk you through alternative payment options.&lt;/li&gt;
      &lt;li&gt;If cost is a problem, consider bootcamps with &lt;a href=&quot;https://www.coursereport.com/blog/coding-bootcamp-deferred-tuition-income-share-agreements&quot;&gt;alternative payment options&lt;/a&gt; like deferred tuition (you aren’t required to make payments until you get a job) or income sharing (your payment is comes as a percentage of your salary once you get hired). Beware that there’s typically a lot of fine print for both of these.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursereport.com/blog/ultimate-guide-to-coding-bootcamp-loans-financing&quot;&gt;Bootcamp loans&lt;/a&gt; can also be a great option.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;What is a bootcamp?&lt;/h1&gt;

&lt;p&gt;I’m going to talk specifically about immersive tech/coding bootcamps. Still, it’s a big category. Bootcamps are also called “accelerated learning programs”; they teach technical skills primarily to people who are new. Most bootcamps are roughly 12 weeks long and in that time they are intended to prepare someone to get their first job in an entirely new field.&lt;/p&gt;

&lt;p&gt;Let’s stop here and just appreciate how tall of an order that is. If someone wants to prepare for an entirely new career, they might go to a 4 year college or get masters degree (&lt;a href=&quot;https://www.usnews.com/higher-education/online-education/articles/2017-05-12/us-news-data-how-long-it-takes-to-earn-an-online-masters-degree&quot;&gt;2+ years with low graduation rates&lt;/a&gt;). These bootcamps try to accomplish the same thing in 3 months for a much, much lower cost.&lt;/p&gt;

&lt;p&gt;That’s an extremely tall order, but for those who get into and complete bootcamps, it tends to work: Course Report &lt;a href=&quot;https://www.coursereport.com/reports/coding-bootcamp-job-placement-2017&quot;&gt;found&lt;/a&gt; that in 2017 “80% of graduates surveyed say they’ve been employed in a job requiring the technical skills learned at bootcamp, with an average salary  increase of 50.5% or $23,724. The average starting salary of a bootcamp grad is $70,698.” One reason this is possible is the immersive bootcamp model, where students are present, full-time,&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;I work for Metis and I’m super proud of what we do, but this guide isn’t an ad for my company. I’m honestly not going to mention Metis very often. But if you really want to know, I think that we’re the best in the business for people interested in Data Science and for whom our immersive bootcamp model and cost structure works. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="Bootcamps" />
      

      
        <summary type="html">note 8/15: this is still a work in progress so check back as I fill it in I’ve been a bootcamp instructor at Metis for about a year now1. It’s been an incredible, rewarding experience and I plan to stick around for a while. In that time, I’ve been asked a lot about bootcamps. People want to know how bootcamps work, if bootcamps are right for them, holy cow are they really $15,000? I’m putting this guide together to answer those questions. This guide is for anyone interested in moving to a technical career, like coding, data science, or similar and are able to participate in an immersive (roughly 3 months of full time work) bootcamp. I especially intend this for people who aren’t already familiar with the tech/coding world and who don’t have ~$15,000 laying around to drop on a bootcamp. My TLDR: Bootcamps are for real. They can be a legitimately great way to start a good career that too few people have access to. First, make sure joining an bootcamp is right for you. Are you likely to finish and likely to be fully committed to the job search after finishing? Be very honest with yourself about this. A great way to figure this out is to complete a bootcamp prep program (many are free). Bootcamp prep is also a great way to figure out which type of bootcamp (like coding vs data science) is right for you. Don’t put too much pressure on getting in and plan to get rejected from your first bootcamp. Bootcamps can be selective and admissions necessarily involves chance. You’ll learn each time you interview. You might have a favorite bootcamp but there are many good ones. Most bootcamps allow you to interview again later if you are rejected. Don’t let cost be an issue. Any decent bootcamp will work with you on payment if you are admitted. They’ll walk you through alternative payment options. If cost is a problem, consider bootcamps with alternative payment options like deferred tuition (you aren’t required to make payments until you get a job) or income sharing (your payment is comes as a percentage of your salary once you get hired). Beware that there’s typically a lot of fine print for both of these. Bootcamp loans can also be a great option. What is a bootcamp? I’m going to talk specifically about immersive tech/coding bootcamps. Still, it’s a big category. Bootcamps are also called “accelerated learning programs”; they teach technical skills primarily to people who are new. Most bootcamps are roughly 12 weeks long and in that time they are intended to prepare someone to get their first job in an entirely new field. Let’s stop here and just appreciate how tall of an order that is. If someone wants to prepare for an entirely new career, they might go to a 4 year college or get masters degree (2+ years with low graduation rates). These bootcamps try to accomplish the same thing in 3 months for a much, much lower cost. That’s an extremely tall order, but for those who get into and complete bootcamps, it tends to work: Course Report found that in 2017 “80% of graduates surveyed say they’ve been employed in a job requiring the technical skills learned at bootcamp, with an average salary increase of 50.5% or $23,724. The average starting salary of a bootcamp grad is $70,698.” One reason this is possible is the immersive bootcamp model, where students are present, full-time, I work for Metis and I’m super proud of what we do, but this guide isn’t an ad for my company. I’m honestly not going to mention Metis very often. But if you really want to know, I think that we’re the best in the business for people interested in Data Science and for whom our immersive bootcamp model and cost structure works. &amp;#8617;</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">How to: Backup iMessages using OSX and Google Drive</title>
      
      
      <link href="http://localhost:4000/2018/03/01/How-to-Backup-iMessages-using-OSX-and-Google-Drive/" rel="alternate" type="text/html" title="How to: Backup iMessages using OSX and Google Drive" />
      
      <published>2018-03-01T12:57:45+00:00</published>
      <updated>2018-03-01T12:57:45+00:00</updated>
      <id>http://localhost:4000/2018/03/01/How-to-Backup-iMessages-using-OSX-and-Google-Drive</id>
      <content type="html" xml:base="http://localhost:4000/2018/03/01/How-to-Backup-iMessages-using-OSX-and-Google-Drive/">&lt;p&gt;This is pretty short but I wanted to leave it here for posterity. The process is to just add the archive folder to Google Drive. You don’t have to move it to your Google Drive folder or hard link, as other tutorials have suggested, just add it to the list of extra folders synced by Google Drive.&lt;/p&gt;

&lt;p&gt;First, find the folder iMessages uses to store all its data. Mine is in &lt;code class=&quot;highlighter-rouge&quot;&gt;/Users/soph/Library/Messages&lt;/code&gt;. If you aren’t able to see the Library folder, use &lt;code class=&quot;highlighter-rouge&quot;&gt;cmd-shift-.&lt;/code&gt; to make hidden items viewable.&lt;/p&gt;

&lt;p&gt;Select the Google  Backup and Sync icon in your menu bar at the top of your screen. Go to …-&amp;gt;Preferences-&amp;gt;Choose Folder and select that folder.&lt;/p&gt;

&lt;p&gt;And, there, you’re done!&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="howto" />
      

      
        <summary type="html">This is pretty short but I wanted to leave it here for posterity. The process is to just add the archive folder to Google Drive. You don’t have to move it to your Google Drive folder or hard link, as other tutorials have suggested, just add it to the list of extra folders synced by Google Drive. First, find the folder iMessages uses to store all its data. Mine is in /Users/soph/Library/Messages. If you aren’t able to see the Library folder, use cmd-shift-. to make hidden items viewable. Select the Google Backup and Sync icon in your menu bar at the top of your screen. Go to …-&amp;gt;Preferences-&amp;gt;Choose Folder and select that folder. And, there, you’re done!</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">A Case for Diversity</title>
      
      
      <link href="http://localhost:4000/2018/02/21/A-Case-for-Diversity/" rel="alternate" type="text/html" title="A Case for Diversity" />
      
      <published>2018-02-21T08:26:09+00:00</published>
      <updated>2018-02-21T08:26:09+00:00</updated>
      <id>http://localhost:4000/2018/02/21/A-Case-for-Diversity</id>
      <content type="html" xml:base="http://localhost:4000/2018/02/21/A-Case-for-Diversity/">&lt;p&gt;Author’s note: This is a pre-publication draft. Parts of this material may appear in subsequent publications. I’m sharing in this format to enable transparency and dialogue but I do not wish to misrepresent the relationship this draft may have with any later work.&lt;/p&gt;

&lt;p&gt;There’s a lot of talk of diversity, especially discussion of the reasons companies and other groups should prioritize diversity.&lt;/p&gt;

&lt;h2&gt;Diversity for fairness&lt;/h2&gt;

&lt;p&gt;One important idea is a general sense of fairness. Careers that pay well should be distributed roughly proportionately among genders, ethnic groups, and other ways of categorizing people. We have the sense that there’s nothing about being male that makes someone a better programmer, or about being white that makes someone a better hedge fund manager. Then fairness suggests to many that, any unevenness in who gets access to these desirable careers reflects a lack of fairness. When a tech company primarily is located in a country where black people make up &lt;a href=&quot;https://en.wikipedia.org/wiki/Demography_of_the_United_States#Race_and_ethnicity&quot;&gt;12% of the population&lt;/a&gt;, but that company’s tech workers are only 1% black (as is true of &lt;a href=&quot;https://diversity.google/commitments/&quot;&gt;Alphabet/Google&lt;/a&gt;, &lt;a href=&quot;https://images-na.ssl-images-amazon.com/images/G/01/DiversityCampaign2016_Q3/EEO-1_2016_consolidated._V525968886_.pdf&quot;&gt;Amazon&lt;/a&gt;, and other tech companies) then &lt;em&gt;something&lt;/em&gt; unfair is going on. Sure, there is some buck-passing here. There are problems at many levels that create unfairness: geographic segregation, school systems, gaps in generational wealth accumulation, gaps in laws. But the culture of many of these tech companies is one that famously &lt;a href=&quot;https://www.inc.com/magazine/201307/christine-lagorio/uber-the-car-service-explosive-growth.html&quot;&gt;fights (and wins!) against structural hurdles like these&lt;/a&gt;. If these companies can &lt;a href=&quot;https://www.wired.com/2012/02/zuck-letter/&quot;&gt;move fast and break things&lt;/a&gt; when it comes to new features and their bottom line, we should expect the same when it comes to fairness.&lt;/p&gt;

&lt;h2&gt;Diversity for social tech&lt;/h2&gt;

&lt;p&gt;There are other reasons companies prioritize diversity, like legal ones, that I won’t get into. Instead I want to focus on something I would like to hear more often and more clearly from the technology world. Independent of everything else, diversity will become essential to the success of any tech company. This is because the products made by tech companies are increasingly cultural ones, embedded in our everyday social lives, and producing social products that are successful requires engineers/designers/etc. who have a social understanding of those who use the products.&lt;/p&gt;

&lt;p&gt;Let’s not forget when Google Maps pronounced Malcolm X Street “Malcolm the Tenth” as if he were a british monarch[&lt;a href=&quot;http://baratunde.com/blog/2013/12/2/google-maps-kings-malcolm-x-as-malcolm-the-10th&quot;&gt;Baratunde Thurston&lt;/a&gt;]; that Facebook’s name policy locks the accounts of trans and gender non-conforming users, including a Facebook employee[&lt;a href=&quot;https://medium.com/@zip/my-name-is-only-real-enough-to-work-at-facebook-not-to-use-on-the-site-c37daf3f4b03&quot;&gt;Zoe Cat&lt;/a&gt;]; when Google Images automatically labeled black people gorillas[&lt;a href=&quot;https://twitter.com/jackyalcine/status/615329515909156865&quot;&gt;Jacky AlcinÃ©&lt;/a&gt;]; the long history of racial and gender bias in face recognition[&lt;a href=&quot;https://www.media.mit.edu/projects/gender-shades/overview/&quot;&gt;Joy Buolamwini: Gender Shades&lt;/a&gt;]; the many cases of technology ignoring dark skin [like &lt;a href=&quot;https://mic.com/articles/124899/the-reason-this-racist-soap-dispenser-doesn-t-work-on-black-skin#.WduRkoEKf&quot;&gt;soap dispensers&lt;/a&gt; and &lt;a href=&quot;https://www.cnet.com/news/how-accurate-are-wristband-heart-rate-monitors/&quot;&gt;heart rate monitors&lt;/a&gt;]. These are just a few examples but they illustrate the point that we are interacting with our technology in social ways. Each of the above examples would have been trivial to catch for an engineer, project manager, or other employee from an underrepresented group.&lt;/p&gt;

&lt;p&gt;What I’m arguing here is that it’s in tech company’s self-interest to seriously prioritize diversity. Even a company that is unconvinced that diversity is important because of fairness or legal reasons should be concerned about how they plan to design products that people interact with in social contexts. These companies will want to ensure that their tech workforce is diverse at every levelâfrom the people writing the code to those deciding which new features to develop and beyondâbecause each of these decisions will become more significantly social as time goes on.&lt;/p&gt;

&lt;p&gt;Diversity to stop algorithmic violence&lt;/p&gt;

&lt;p&gt;One specific concern involves the idea of algorithmic violence[&lt;a href=&quot;https://github.com/MimiOnuoha/On-Algorithmic-Violence&quot;&gt;Mimi Onuoha&lt;/a&gt;], a term coined by Mimi Onuoha that refers to the ways that automated decision-making does real harm to people. In college I studied Computer Engineering and took an ethics course along with civil and mechanical engineers where we discussed the ethical challenges involved in designing walkways and other physical things. What was missing then, and seems to largely be missing now, is a serious look at how decisions made in technology companies, including by software developers and data scientists, lead to real consequences.&lt;/p&gt;

&lt;p&gt;Some algorithmic violence is quite easy to see, such as when Palantir (one of the most valuable data companies and one that was recently sued for racial discrimination[&lt;a href=&quot;https://www.vanityfair.com/news/2016/09/us-government-sues-palantir-discrimination&quot;&gt;Vanity Fair&lt;/a&gt;]) builds an enormous data machine for the targeting and tracking of immigrants for deportation[&lt;a href=&quot;https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/&quot;&gt;The Intercept&lt;/a&gt;]. In most cases, though, algorithmic violence is less than obvious. Guillaume Chaslot writes[&lt;a href=&quot;https://medium.com/@guillaumechaslot/how-algorithms-can-learn-to-discredit-the-media-d1360157c4fa&quot;&gt;Medium&lt;/a&gt;] that YouTube’s massive recommendation engine, one that he helped design, is tasked with maximizing users’ viewing time. The recommendation engine does this in a single-minded way that ignores the effects that the kind of content one cannot turn away from (like disturbing videos targeted at kids[&lt;a href=&quot;https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2&quot;&gt;Medium&lt;/a&gt;] and conspiracy theories[&lt;a href=&quot;https://www.vanityfair.com/news/2018/02/youtube-conspiracy-problem&quot;&gt;Vanity Fair&lt;/a&gt;]) might have on its viewers and even elections[&lt;a href=&quot;https://medium.com/the-graph/youtubes-ai-is-neutral-towards-clicks-but-is-biased-towards-people-and-ideas-3a2f643dea9a&quot;&gt;Chaslot @ Medium&lt;/a&gt;]. In ‘Automating Inequality’[&lt;a href=&quot;http://www.strandbooks.com/sociology/automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor/&quot;&gt;Strand&lt;/a&gt;] Virginia Eubanks provides an extensive catalogue of ways that seemingly âobjective’ automated systems harm vulnerable people, whether they were set up to do so intentionally or not.&lt;/p&gt;

&lt;p&gt;Algorithmic violence is a problem, like information security and global warming, that is virtually guaranteed to become more important with time. Because the effects of algorithmic violence are often hidden except to those who are affected by it, companies without a diverse workforce will be at a disadvantage when trying to recognize and prevent such violence. So prioritizing diversity is one of the many steps, like a Hippocratic oath for technology[&lt;a href=&quot;https://twitter.com/the_CityLion/status/954109076748820481&quot;&gt;Marie&lt;/a&gt;], we need to take to counter algorithmic violence.&lt;/p&gt;

&lt;p&gt;Recommended readings:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Weapons of Math Destruction by Cathy O’Neil - [Strand link to purchase] (http://www.strandbooks.com/political-science/weapons-of-math-destruction-how-big-data-increases-inequality-and-threatens-democracy-0553418831/)&lt;/li&gt;
  &lt;li&gt;Automating Inequality by Virginia Eubanks - [Strand link to purchase] (http://www.strandbooks.com/sociology/automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor/)&lt;/li&gt;
  &lt;li&gt;On Algorithmic Violence by Mimi Onuoha - [github link] (https://github.com/MimiOnuoha/On-Algorithmic-Violence)&lt;/li&gt;
  &lt;li&gt;Gender Shades, research project led by Joy Buolamwini - &lt;a href=&quot;https://dam-prod.media.mit.edu/x/2018/02/06/Gender%20Shades%20Intersectional%20Accuracy%20Disparities.pdf&quot;&gt;2018 paper by Buolamwini and Gebru&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      

      
        <summary type="html">Author’s note: This is a pre-publication draft. Parts of this material may appear in subsequent publications. I’m sharing in this format to enable transparency and dialogue but I do not wish to misrepresent the relationship this draft may have with any later work. There’s a lot of talk of diversity, especially discussion of the reasons companies and other groups should prioritize diversity. Diversity for fairness One important idea is a general sense of fairness. Careers that pay well should be distributed roughly proportionately among genders, ethnic groups, and other ways of categorizing people. We have the sense that there’s nothing about being male that makes someone a better programmer, or about being white that makes someone a better hedge fund manager. Then fairness suggests to many that, any unevenness in who gets access to these desirable careers reflects a lack of fairness. When a tech company primarily is located in a country where black people make up 12% of the population, but that company’s tech workers are only 1% black (as is true of Alphabet/Google, Amazon, and other tech companies) then something unfair is going on. Sure, there is some buck-passing here. There are problems at many levels that create unfairness: geographic segregation, school systems, gaps in generational wealth accumulation, gaps in laws. But the culture of many of these tech companies is one that famously fights (and wins!) against structural hurdles like these. If these companies can move fast and break things when it comes to new features and their bottom line, we should expect the same when it comes to fairness. Diversity for social tech There are other reasons companies prioritize diversity, like legal ones, that I won’t get into. Instead I want to focus on something I would like to hear more often and more clearly from the technology world. Independent of everything else, diversity will become essential to the success of any tech company. This is because the products made by tech companies are increasingly cultural ones, embedded in our everyday social lives, and producing social products that are successful requires engineers/designers/etc. who have a social understanding of those who use the products. Let’s not forget when Google Maps pronounced Malcolm X Street “Malcolm the Tenth” as if he were a british monarch[Baratunde Thurston]; that Facebook’s name policy locks the accounts of trans and gender non-conforming users, including a Facebook employee[Zoe Cat]; when Google Images automatically labeled black people gorillas[Jacky AlcinÃ©]; the long history of racial and gender bias in face recognition[Joy Buolamwini: Gender Shades]; the many cases of technology ignoring dark skin [like soap dispensers and heart rate monitors]. These are just a few examples but they illustrate the point that we are interacting with our technology in social ways. Each of the above examples would have been trivial to catch for an engineer, project manager, or other employee from an underrepresented group. What I’m arguing here is that it’s in tech company’s self-interest to seriously prioritize diversity. Even a company that is unconvinced that diversity is important because of fairness or legal reasons should be concerned about how they plan to design products that people interact with in social contexts. These companies will want to ensure that their tech workforce is diverse at every levelâfrom the people writing the code to those deciding which new features to develop and beyondâbecause each of these decisions will become more significantly social as time goes on. Diversity to stop algorithmic violence One specific concern involves the idea of algorithmic violence[Mimi Onuoha], a term coined by Mimi Onuoha that refers to the ways that automated decision-making does real harm to people. In college I studied Computer Engineering and took an ethics course along with civil and mechanical engineers where we discussed the ethical challenges involved in designing walkways and other physical things. What was missing then, and seems to largely be missing now, is a serious look at how decisions made in technology companies, including by software developers and data scientists, lead to real consequences. Some algorithmic violence is quite easy to see, such as when Palantir (one of the most valuable data companies and one that was recently sued for racial discrimination[Vanity Fair]) builds an enormous data machine for the targeting and tracking of immigrants for deportation[The Intercept]. In most cases, though, algorithmic violence is less than obvious. Guillaume Chaslot writes[Medium] that YouTube’s massive recommendation engine, one that he helped design, is tasked with maximizing users’ viewing time. The recommendation engine does this in a single-minded way that ignores the effects that the kind of content one cannot turn away from (like disturbing videos targeted at kids[Medium] and conspiracy theories[Vanity Fair]) might have on its viewers and even elections[Chaslot @ Medium]. In ‘Automating Inequality’[Strand] Virginia Eubanks provides an extensive catalogue of ways that seemingly âobjective’ automated systems harm vulnerable people, whether they were set up to do so intentionally or not. Algorithmic violence is a problem, like information security and global warming, that is virtually guaranteed to become more important with time. Because the effects of algorithmic violence are often hidden except to those who are affected by it, companies without a diverse workforce will be at a disadvantage when trying to recognize and prevent such violence. So prioritizing diversity is one of the many steps, like a Hippocratic oath for technology[Marie], we need to take to counter algorithmic violence. Recommended readings: Weapons of Math Destruction by Cathy O’Neil - [Strand link to purchase] (http://www.strandbooks.com/political-science/weapons-of-math-destruction-how-big-data-increases-inequality-and-threatens-democracy-0553418831/) Automating Inequality by Virginia Eubanks - [Strand link to purchase] (http://www.strandbooks.com/sociology/automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor/) On Algorithmic Violence by Mimi Onuoha - [github link] (https://github.com/MimiOnuoha/On-Algorithmic-Violence) Gender Shades, research project led by Joy Buolamwini - 2018 paper by Buolamwini and Gebru</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Soph’s VM tweaks</title>
      
      
      <link href="http://localhost:4000/2018/02/14/Soph-s-VM-tweaks/" rel="alternate" type="text/html" title="Soph's VM tweaks" />
      
      <published>2018-02-14T11:11:48+00:00</published>
      <updated>2018-02-14T11:11:48+00:00</updated>
      <id>http://localhost:4000/2018/02/14/Soph-s-VM-tweaks</id>
      <content type="html" xml:base="http://localhost:4000/2018/02/14/Soph-s-VM-tweaks/">&lt;h1&gt;What’s this&lt;/h1&gt;

&lt;p&gt;(hi, this is a test)&lt;/p&gt;

&lt;p&gt;This is a scratch pad for me to use when I set up new virtual machines. I’m sharing it in case anyone else is interested.&lt;/p&gt;

&lt;h1&gt;fish is by far my favorite shell&lt;/h1&gt;

&lt;p&gt;Install it and configure it following &lt;a href=&quot;https://geowarin.github.io/the-missing-fish-shell-tutorial.html&quot;&gt;this tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/oh-my-fish/oh-my-fish&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;omf&lt;/code&gt;&lt;/a&gt; is a handy package manager for fish.&lt;/p&gt;

&lt;p&gt;I use the &lt;a href=&quot;https://github.com/oh-my-fish/plugin-foreign-env&quot;&gt;foreign environment interface&lt;/a&gt; to load my &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bash_profile&lt;/code&gt; and similar. (&lt;a href=&quot;https://superuser.com/a/1162592&quot;&gt;Thank you&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;You can install &lt;a href=&quot;https://github.com/oh-my-fish/oh-my-fish/blob/master/docs/Themes.md#sushi&quot;&gt;themes&lt;/a&gt; with it and my fav is probably &lt;code class=&quot;highlighter-rouge&quot;&gt;sushi&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you’re using anaconda, you’ll have to remember to use &lt;code class=&quot;highlighter-rouge&quot;&gt;activate&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;source activate&lt;/code&gt; &lt;a href=&quot;https://github.com/conda/conda/issues/2611#issuecomment-230894534&quot;&gt;details&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;tmux&lt;/h1&gt;

&lt;p&gt;I love tmux! I p much always install it first thing. To make it more useful, I add options by creating the following file at &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.tmux.conf&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set-option -g mouse on
set-option -g default-command /usr/bin/fish
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1&gt;other tools&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;install &lt;a href=&quot;https://github.com/moonpyk/dtrx&quot;&gt;dtrx&lt;/a&gt; for common sense file extraction
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt install dtrx&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://glances.readthedocs.io/en/stable/index.html&quot;&gt;glances&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/wookayin/gpustat&quot;&gt;gpustat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Access Jupyter from your server&lt;/h1&gt;

&lt;p&gt;I typically set up a jupyter server mostly according to Chris Albon’s instructions &lt;a href=&quot;https://chrisalbon.com/software_engineering/cloud_computing/run_project_jupyter_on_amazon_ec2/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;Start Jupyter on restart&lt;/h1&gt;

&lt;p&gt;Previously, my workflow was something like this: go to console in browser and start ec2, go to terminal and mosh into ec2, start jupyter notebook, go back to
browser and use jupyter. That’s an annoying amount of steps. I like to simplify this so that on every device restart, my machine automagically starts a jupyter notebook server and glances (which I use to monitor the machine’s resource usage).&lt;/p&gt;

&lt;p&gt;Here’s the solution I found, which is a modification of &lt;a href=&quot;http://rodriguezandres.github.io/2017/01/18/jupyter-aws/&quot;&gt;this&lt;/a&gt;. Modify your &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/rc.local&lt;/code&gt; to include the following above the &lt;code class=&quot;highlighter-rouge&quot;&gt;exit 0&lt;/code&gt; line:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:/home/ubuntu/miniconda3/bin&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;jupyter notebook &lt;span class=&quot;nt&quot;&gt;--notebook-dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/ubuntu/ &amp;amp;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;glances &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; &amp;amp;

&lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      

      
        <summary type="html">What’s this (hi, this is a test) This is a scratch pad for me to use when I set up new virtual machines. I’m sharing it in case anyone else is interested. fish is by far my favorite shell Install it and configure it following this tutorial omf is a handy package manager for fish. I use the foreign environment interface to load my ~/.bash_profile and similar. (Thank you) You can install themes with it and my fav is probably sushi. If you’re using anaconda, you’ll have to remember to use activate instead of source activate details. tmux I love tmux! I p much always install it first thing. To make it more useful, I add options by creating the following file at ~/.tmux.conf. set-option -g mouse on set-option -g default-command /usr/bin/fish other tools install dtrx for common sense file extraction sudo apt install dtrx glances gpustat Access Jupyter from your server I typically set up a jupyter server mostly according to Chris Albon’s instructions here. Start Jupyter on restart Previously, my workflow was something like this: go to console in browser and start ec2, go to terminal and mosh into ec2, start jupyter notebook, go back to browser and use jupyter. That’s an annoying amount of steps. I like to simplify this so that on every device restart, my machine automagically starts a jupyter notebook server and glances (which I use to monitor the machine’s resource usage). Here’s the solution I found, which is a modification of this. Modify your /etc/rc.local to include the following above the exit 0 line: export PATH=&quot;$PATH:/home/ubuntu/miniconda3/bin&quot; nohup jupyter notebook --notebook-dir=/home/ubuntu/ &amp;amp; nohup glances -w &amp;amp; exit 0</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Paperspace how-to (cheap cloud GPU)</title>
      
      
      <link href="http://localhost:4000/2018/02/01/Paperspace-how-to-cheap-cloud-GPU/" rel="alternate" type="text/html" title="Paperspace how-to (cheap cloud GPU)" />
      
      <published>2018-02-01T16:11:40+00:00</published>
      <updated>2018-02-01T16:11:40+00:00</updated>
      <id>http://localhost:4000/2018/02/01/Paperspace-how-to-cheap-cloud-GPU</id>
      <content type="html" xml:base="http://localhost:4000/2018/02/01/Paperspace-how-to-cheap-cloud-GPU/">&lt;p&gt;The use of GPUs have become quite important for applications of Deep Learning. The landscape of this hardware has lately become quite interesting. The &lt;a href=&quot;https://arstechnica.com/tech-policy/2018/01/cryptocurrency-boom-creates-insane-global-graphics-card-shortage/&quot;&gt;cryptocurrency fad&lt;/a&gt; has led to GPUs becoming expensive and/or unavailable. One solution to this problem is to rent a computer with a GPU from Google, Amazon, Microsoft, and others. Google even &lt;a href=&quot;https://cloudplatform.googleblog.com/2017/11/new-lower-prices-for-GPUs-and-preemptible-Local-SSDs.html&quot;&gt;recently lowered&lt;/a&gt; their GPU prices quite substantially. I’ll save doing a full comparison of each platform for later, but what I’ll go over today is getting started with a relatively new service, &lt;a href=&quot;https://techcrunch.com/2017/05/03/paperspace-launches-gpu-powered-virtual-machines-loaded-with-tools-for-data-scientists/&quot;&gt;PaperSpace&lt;/a&gt; based in my home of Brooklyn &amp;lt;3.&lt;/p&gt;

&lt;p&gt;The virtue of paperspace is that their entry-level GPU offering costs $0.40/hr (compared to Google’s new $0.45/hr and Amazon’s $0.90/hr) but &lt;a href=&quot;https://medium.com/initialized-capital/benchmarking-tensorflow-performance-and-cost-across-different-gpu-options-69bd85fe5d58&quot;&gt;benchmarks ahead&lt;/a&gt; of Amazon and other offers based on the Tesla K80.&lt;/p&gt;

&lt;p&gt;Below, I’ll show you how to get up and running quickly and how to set up cost-saving measures, like auto-shutdown.&lt;/p&gt;

&lt;h1&gt;Steps to get running&lt;/h1&gt;

&lt;p&gt;First, as with any new machine, update the current packages with&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt update
sudo apt upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(Note: I had to add the &lt;code class=&quot;highlighter-rouge&quot;&gt;--fix-missing&lt;/code&gt; flag to &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt update&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Add a new user according to &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-ubuntu-quickstart&quot;&gt;these instructions&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;open ports with ufw&lt;/h2&gt;

&lt;p&gt;By default, Paperspace has a very strict firewall (this is a good thing). We’re going to want to get to our jupyter notebooks, though, so we need to open up some ports. You can do that with &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server&quot;&gt;these instructions&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My version is pretty unsafe (it allows access from any IP) so feel free to check that link for info on restricting the IP that can access your jupyter port.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ufw allow 8888
sudo ufw allow 60000:61000/udp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1&gt;set up jupyter&lt;/h1&gt;

&lt;h1&gt;fix autoshutdown with ssh&lt;/h1&gt;

&lt;p&gt;https://paperspace.zendesk.com/hc/en-us/articles/115002807447-How-do-I-use-Auto-Shutdown-on-my-Linux-machine-when-connecting-through-SSH-&lt;/p&gt;

&lt;h1&gt;set up ssh keys&lt;/h1&gt;

&lt;p&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys–2&lt;/p&gt;

&lt;p&gt;https://apple.stackexchange.com/questions/48502/how-can-i-permanently-add-my-ssh-private-key-to-keychain-so-it-is-automatically&lt;/p&gt;

&lt;h1&gt;Install cuda 9.1&lt;/h1&gt;

&lt;p&gt;You can use the &lt;a href=&quot;http://docs.nvidia.com/cuda/cuda-installation-guide-linux/&quot;&gt;official guide&lt;/a&gt; but I prefer &lt;a href=&quot;https://askubuntu.com/questions/967332/how-can-i-install-cuda-9-on-ubuntu-17-10&quot;&gt;these instructions&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;Install cudnn&lt;/h1&gt;

&lt;p&gt;http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="drafts" />
      

      
        <summary type="html">The use of GPUs have become quite important for applications of Deep Learning. The landscape of this hardware has lately become quite interesting. The cryptocurrency fad has led to GPUs becoming expensive and/or unavailable. One solution to this problem is to rent a computer with a GPU from Google, Amazon, Microsoft, and others. Google even recently lowered their GPU prices quite substantially. I’ll save doing a full comparison of each platform for later, but what I’ll go over today is getting started with a relatively new service, PaperSpace based in my home of Brooklyn &amp;lt;3. The virtue of paperspace is that their entry-level GPU offering costs $0.40/hr (compared to Google’s new $0.45/hr and Amazon’s $0.90/hr) but benchmarks ahead of Amazon and other offers based on the Tesla K80. Below, I’ll show you how to get up and running quickly and how to set up cost-saving measures, like auto-shutdown. Steps to get running First, as with any new machine, update the current packages with sudo apt update sudo apt upgrade (Note: I had to add the --fix-missing flag to sudo apt update) Add a new user according to these instructions. open ports with ufw By default, Paperspace has a very strict firewall (this is a good thing). We’re going to want to get to our jupyter notebooks, though, so we need to open up some ports. You can do that with these instructions. My version is pretty unsafe (it allows access from any IP) so feel free to check that link for info on restricting the IP that can access your jupyter port. sudo ufw allow 8888 sudo ufw allow 60000:61000/udp set up jupyter fix autoshutdown with ssh https://paperspace.zendesk.com/hc/en-us/articles/115002807447-How-do-I-use-Auto-Shutdown-on-my-Linux-machine-when-connecting-through-SSH- set up ssh keys https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys–2 https://apple.stackexchange.com/questions/48502/how-can-i-permanently-add-my-ssh-private-key-to-keychain-so-it-is-automatically Install cuda 9.1 You can use the official guide but I prefer these instructions. Install cudnn http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Deep Learning Tips</title>
      
      
      <link href="http://localhost:4000/2017/12/04/Deep-Learning-Tips/" rel="alternate" type="text/html" title="Deep Learning Tips" />
      
      <published>2017-12-04T13:15:11+00:00</published>
      <updated>2017-12-04T13:15:11+00:00</updated>
      <id>http://localhost:4000/2017/12/04/Deep-Learning-Tips</id>
      <content type="html" xml:base="http://localhost:4000/2017/12/04/Deep-Learning-Tips/">&lt;p&gt;I often find myself in roughly this situation:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I’ve done a lot of work to pre-process data, researched different DL architectures and selected one (or more), modified it so that it works well on my data.
And now I’ve got a model that does well, but not quite as well as I want it to.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Below I’ll outline steps that I find very useful in this situation. Of course, more detail about how to get to that point is for another post. Also, I’m using Keras so many of these are specific to that tool, but they could absolutely be applied to other DL packages.&lt;/p&gt;

&lt;h2&gt;Clean up training code and improve logging.&lt;/h2&gt;

&lt;p&gt;My typical workflow when I’m building or tweaking a model by hand is to run Kears in a Jupyter notebook. This works fine if the entire pipeline runs in a few minutes but doesn’t work if I need to close my laptop while the pipeline is running. Jupyter often has trouble gracefully reconnecting and then I lose all the &lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt; info.&lt;/p&gt;

&lt;p&gt;Porting my code into a self-contained python script allows me to connect to a machine over mosh and tmux, run the script, and then forget about it. This is handy on it’s own but it’ll be extremely handy when we get to the later tips.&lt;/p&gt;

&lt;p&gt;The tools I use for this are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/callbacks/#csvlogger&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.CSVLogger(...)&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/callbacks/#tensorboard&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.TensorBoard(...)&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/callbacks/#modelcheckpoint&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.ModelCheckpoint(..., save_best_only=True)&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CSVLogger&lt;/code&gt; takes the output from verbose and stores it in a csv file for later. If you’re using tmux, it should be preserving your terminal log (and the &lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt; output) but csv puts all of that history data in a format where you can easily use it.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TensorBoard&lt;/code&gt; is super handy if you want to be able to monitor the progress of a long-running model from somewhere other than your terminal. I can access this from my iPad and it looks great!
&lt;img src=&quot;/images/tips/tb.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ModelCheckpoint&lt;/code&gt; saves your model every so often (you set the frequency as a parameter). This is nice on its own because it allows you to access a model that was trained in a script from anywhere (including my preferred tinkering environment, Jupyter). Even more than that, if you use &lt;code class=&quot;highlighter-rouge&quot;&gt;save_best_only=True&lt;/code&gt;, then the script is automatically saving space by only saving the best performing model (you should youse &lt;code class=&quot;highlighter-rouge&quot;&gt;val_loss&lt;/code&gt; or some other validation metric with this option).&lt;/p&gt;

&lt;h2&gt;Learning Rate Schedule&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/callbacks/#learningratescheduler&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.LearningRateScheduler&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/callbacks/#reducelronplateau&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;keras.callbacks.ReduceLROnPlateau&lt;/code&gt;&lt;/a&gt; This is my preference. I use this in conjunction with EarlyStopping and ModelCheckpoint all the time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Use noise and other transformations to enlarge your datasets&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/preprocessing/image/#imagedatagenerator&quot;&gt;keras.preprocessing.image.ImageDataGenerator()&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tensorflow.org/versions/master/tutorials/audio_recognition#background_noise&quot;&gt;Tensorflow blog discussing this with background noise&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Optimize&lt;/h2&gt;

&lt;p&gt;There are many hyperparameters that can be optimized:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Learning rate&lt;/li&gt;
  &lt;li&gt;Dropout rate&lt;/li&gt;
  &lt;li&gt;Preprocessing steps&lt;/li&gt;
  &lt;li&gt;Different architectures (size and shape of layers as well as count) and parameters&lt;/li&gt;
  &lt;li&gt;Regularizers and parameters&lt;/li&gt;
  &lt;li&gt;Initializers and parameters&lt;/li&gt;
  &lt;li&gt;and more!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These create an enormous space of possible models for which to test. My recommendation is to find something that works and then from that functioning model determine plausible options for the above hyperparameters. Then throw what you have into hyperopt.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/hyperopt/hyperopt&quot;&gt;HyperOpt does this automatically&lt;/a&gt;. It’s poorly documented but fairly easy to use.&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      

      
        <summary type="html">I often find myself in roughly this situation: I’ve done a lot of work to pre-process data, researched different DL architectures and selected one (or more), modified it so that it works well on my data. And now I’ve got a model that does well, but not quite as well as I want it to. Below I’ll outline steps that I find very useful in this situation. Of course, more detail about how to get to that point is for another post. Also, I’m using Keras so many of these are specific to that tool, but they could absolutely be applied to other DL packages. Clean up training code and improve logging. My typical workflow when I’m building or tweaking a model by hand is to run Kears in a Jupyter notebook. This works fine if the entire pipeline runs in a few minutes but doesn’t work if I need to close my laptop while the pipeline is running. Jupyter often has trouble gracefully reconnecting and then I lose all the verbose info. Porting my code into a self-contained python script allows me to connect to a machine over mosh and tmux, run the script, and then forget about it. This is handy on it’s own but it’ll be extremely handy when we get to the later tips. The tools I use for this are: keras.callbacks.CSVLogger(...) keras.callbacks.TensorBoard(...) keras.callbacks.ModelCheckpoint(..., save_best_only=True) CSVLogger takes the output from verbose and stores it in a csv file for later. If you’re using tmux, it should be preserving your terminal log (and the verbose output) but csv puts all of that history data in a format where you can easily use it. TensorBoard is super handy if you want to be able to monitor the progress of a long-running model from somewhere other than your terminal. I can access this from my iPad and it looks great! ModelCheckpoint saves your model every so often (you set the frequency as a parameter). This is nice on its own because it allows you to access a model that was trained in a script from anywhere (including my preferred tinkering environment, Jupyter). Even more than that, if you use save_best_only=True, then the script is automatically saving space by only saving the best performing model (you should youse val_loss or some other validation metric with this option). Learning Rate Schedule keras.callbacks.LearningRateScheduler keras.callbacks.ReduceLROnPlateau This is my preference. I use this in conjunction with EarlyStopping and ModelCheckpoint all the time. Use noise and other transformations to enlarge your datasets keras.preprocessing.image.ImageDataGenerator() Tensorflow blog discussing this with background noise Optimize There are many hyperparameters that can be optimized: Learning rate Dropout rate Preprocessing steps Different architectures (size and shape of layers as well as count) and parameters Regularizers and parameters Initializers and parameters and more! These create an enormous space of possible models for which to test. My recommendation is to find something that works and then from that functioning model determine plausible options for the above hyperparameters. Then throw what you have into hyperopt. HyperOpt does this automatically. It’s poorly documented but fairly easy to use.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Deep learning from scratch with python</title>
      
      
      <link href="http://localhost:4000/2017/10/18/scratch/" rel="alternate" type="text/html" title="Deep learning from scratch with python" />
      
      <published>2017-10-18T10:09:10+00:00</published>
      <updated>2017-10-18T10:09:10+00:00</updated>
      <id>http://localhost:4000/2017/10/18/scratch</id>
      <content type="html" xml:base="http://localhost:4000/2017/10/18/scratch/">&lt;p&gt;Last week I presented at the &lt;a href=&quot;https://web.archive.org/web/20171018141234/https://www.meetup.com/NYC-Data-Science-Study-Group/events/243747107/&quot;&gt;Data Science Study Group&lt;/a&gt; on a project of mine where I built a deep learning platform from scratch in python.&lt;/p&gt;

&lt;p&gt;For reference, here’s my &lt;a href=&quot;https://github.com/sophiaray/sophscratch&quot;&gt;code&lt;/a&gt; and &lt;a href=&quot;http://soph.info/scratch.pdf&quot;&gt;slides&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, my project drew primarily from two sets of sources, without which I never would have completed this project. First, there are many examples of folks doing this online. Here’s an incomplete list in python:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;** &lt;a href=&quot;http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/&quot;&gt;Deep Learning From Scratch I-V&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/deepideas_net&quot;&gt;Daniel Sabinasz&lt;/a&gt; **&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/&quot;&gt;Implementing a Neural Network from Scratch in Python – An Introduction&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/dennybritz&quot;&gt;Denny Britz&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/&quot;&gt;Understanding and coding Neural Networks From Scratch in Python and R&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/sunil2ray?lang=en&quot;&gt;Sunil Ray&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/&quot;&gt;How to Implement the Backpropagation Algorithm From Scratch In Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While all of these are useful, Sabinasz’s was what I based my project on because he implements a system that builds a computational graph and includes a true backpropogation algorithm. The others I saw do this implicitly by calculating the gradients operation-by-operation. That approach is fine for a single demo but I wanted something that mimicked the flexibility of tensorflow, allowing me to compare different network structures and activations without starting over each time.&lt;/p&gt;

&lt;p&gt;In addition to these resources, I drew heavily from &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;Deep Learning&lt;/a&gt; by Goodfellow, Bengio, and Courville. I’m certain that the other examples I looked toward used this book as well.&lt;/p&gt;

&lt;p&gt;While I started with Sabinasz’s code, I made a few modifications and improvements including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add graph visualization with &lt;a href=&quot;http://graphviz.readthedocs.io/en/stable/manual.html&quot;&gt;python Graphviz&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Remove the use of globals for the computational graph&lt;/li&gt;
  &lt;li&gt;Simplify backprop algorithm by adding gradient calculations to the operation classes&lt;/li&gt;
  &lt;li&gt;Add a Relu activation function&lt;/li&gt;
  &lt;li&gt;Tweak the visualizations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s the learning rate plotted along with the classification boundary for a relu network with 4 hidden nodes.
&lt;img src=&quot;/images/relu-w-hidden-nodes.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And here’s the computational graph. You can really see the benefit of tracking the graph and automating the backprop algorithm for a graph of this size.
&lt;img src=&quot;/images/relu-graph.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;What I still want to do&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;I want to write up a blog summarizing my talk and the process for creating this. I think it could be a very useful explanatory tool.&lt;/li&gt;
  &lt;li&gt;I have a strong feeling that some of the gradients in here are inaccurate.
    &lt;ul&gt;
      &lt;li&gt;In many cases the network fails to learn for any learning rate schedule unless I give it a much higher capacity than it needs (e.g. 4+ hidden nodes in the XOR task).&lt;/li&gt;
      &lt;li&gt;In simple cases, like separable data, the model should be able to get arbitrarily close to $J=0$ but fails to do so.&lt;/li&gt;
      &lt;li&gt;The softmax gradient seems to differ from that found in other sources&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I want to extend this model to larger datasets and deeper networks. Right now it runs into what I think are underflow errors in these cases but they should be possible to avoid.&lt;/li&gt;
&lt;/ol&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      
        <category term="Deep" />
      
        <category term="learning," />
      
        <category term="Data" />
      
        <category term="Science," />
      
        <category term="Python" />
      

      
        <summary type="html">Last week I presented at the Data Science Study Group on a project of mine where I built a deep learning platform from scratch in python. For reference, here’s my code and slides. First, my project drew primarily from two sets of sources, without which I never would have completed this project. First, there are many examples of folks doing this online. Here’s an incomplete list in python: ** Deep Learning From Scratch I-V by Daniel Sabinasz ** Implementing a Neural Network from Scratch in Python – An Introduction by Denny Britz Understanding and coding Neural Networks From Scratch in Python and R by Sunil Ray How to Implement the Backpropagation Algorithm From Scratch In Python While all of these are useful, Sabinasz’s was what I based my project on because he implements a system that builds a computational graph and includes a true backpropogation algorithm. The others I saw do this implicitly by calculating the gradients operation-by-operation. That approach is fine for a single demo but I wanted something that mimicked the flexibility of tensorflow, allowing me to compare different network structures and activations without starting over each time. In addition to these resources, I drew heavily from Deep Learning by Goodfellow, Bengio, and Courville. I’m certain that the other examples I looked toward used this book as well. While I started with Sabinasz’s code, I made a few modifications and improvements including: Add graph visualization with python Graphviz Remove the use of globals for the computational graph Simplify backprop algorithm by adding gradient calculations to the operation classes Add a Relu activation function Tweak the visualizations Here’s the learning rate plotted along with the classification boundary for a relu network with 4 hidden nodes. And here’s the computational graph. You can really see the benefit of tracking the graph and automating the backprop algorithm for a graph of this size. What I still want to do I want to write up a blog summarizing my talk and the process for creating this. I think it could be a very useful explanatory tool. I have a strong feeling that some of the gradients in here are inaccurate. In many cases the network fails to learn for any learning rate schedule unless I give it a much higher capacity than it needs (e.g. 4+ hidden nodes in the XOR task). In simple cases, like separable data, the model should be able to get arbitrarily close to $J=0$ but fails to do so. The softmax gradient seems to differ from that found in other sources I want to extend this model to larger datasets and deeper networks. Right now it runs into what I think are underflow errors in these cases but they should be possible to avoid.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Trans fam, update your documents!</title>
      
      
      <link href="http://localhost:4000/2017/07/26/Documents/" rel="alternate" type="text/html" title="Trans fam, update your documents!" />
      
      <published>2017-07-26T11:18:04+00:00</published>
      <updated>2017-07-26T11:18:04+00:00</updated>
      <id>http://localhost:4000/2017/07/26/Documents</id>
      <content type="html" xml:base="http://localhost:4000/2017/07/26/Documents/">&lt;p&gt;Trans friends, here’s a periodic reminder that it might be useful to update your documents (name, gender marker, id). I’ve recently done this. Here’s the quickest and cheapest path for US citizens:&lt;/p&gt;

&lt;p&gt;1 &lt;strong&gt;Update your passport gender marker.&lt;/strong&gt; For this you need proof of citizenship (like a birth certificate), a letter from your doctor, and a new passport photo. Use the template in the link below. The cost is $110 and this can be done in one or two days. &lt;a href=&quot;https://travel.state.gov/content/passports/en/passports/information/gender.html&quot;&gt;info here&lt;/a&gt;
2 &lt;strong&gt;Update your name in court.&lt;/strong&gt; This process differs state by state. Roughly, you’ll schedule a hearing, gather documents including a birth certificate, publish an announcement in the paper (trans folks are generally able to waive the publication requirement in NY), then get certified copies of the court order &lt;a href=&quot;https://srlp.org/resources/namechange/&quot;&gt;NYC&lt;/a&gt;, &lt;a href=&quot;http://www.nycourts.gov/CourtHelp/DIY/nameChange.shtml&quot;&gt;NY&lt;/a&gt;, &lt;a href=&quot;https://slwordpress.rutgers.edu/socialjustice/wp-content/uploads/sites/51/2016/08/NJ-Name-Gender-Change-Guide-for-Residents-v1-1.pdf&quot;&gt;NJ&lt;/a&gt;
3 &lt;strong&gt;Update your passport name.&lt;/strong&gt; Do this within a year of step one and it’s free and only requires the court order (&lt;a href=&quot;https://eforms.state.gov/Forms/ds5504.pdf&quot;&gt;form here&lt;/a&gt;).
4 Everything else (except sometimes a birth certificate) can be done with an updated passport and possibly some additional documentation.&lt;/p&gt;

&lt;p&gt;If you need help, I’d love to or help find someone who can. If money is a problem, &lt;a href=&quot;https://www.transassistance.org&quot;&gt;Trans Assistance Project&lt;/a&gt;, &lt;a href=&quot;http://tldef.org&quot;&gt;TLDEF&lt;/a&gt;, &lt;a href=&quot;https://srlp.org&quot;&gt;SRLP&lt;/a&gt;, and other places have provided that in the past. Let me know if you have any trouble.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      

      
        <summary type="html">Trans friends, here’s a periodic reminder that it might be useful to update your documents (name, gender marker, id). I’ve recently done this. Here’s the quickest and cheapest path for US citizens: 1 Update your passport gender marker. For this you need proof of citizenship (like a birth certificate), a letter from your doctor, and a new passport photo. Use the template in the link below. The cost is $110 and this can be done in one or two days. info here 2 Update your name in court. This process differs state by state. Roughly, you’ll schedule a hearing, gather documents including a birth certificate, publish an announcement in the paper (trans folks are generally able to waive the publication requirement in NY), then get certified copies of the court order NYC, NY, NJ 3 Update your passport name. Do this within a year of step one and it’s free and only requires the court order (form here). 4 Everything else (except sometimes a birth certificate) can be done with an updated passport and possibly some additional documentation. If you need help, I’d love to or help find someone who can. If money is a problem, Trans Assistance Project, TLDEF, SRLP, and other places have provided that in the past. Let me know if you have any trouble.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Sophia</title>
      
      
      <link href="http://localhost:4000/2016/04/02/sophia/" rel="alternate" type="text/html" title="Sophia" />
      
      <published>2016-04-02T00:00:00+00:00</published>
      <updated>2016-04-02T00:00:00+00:00</updated>
      <id>http://localhost:4000/2016/04/02/sophia</id>
      <content type="html" xml:base="http://localhost:4000/2016/04/02/sophia/">&lt;p&gt;One thing about being trans is that I get to come up with my own name. Plenty of non-trans people do this, sure, but to me it sort of feels like a rite of passage for trans folk. I’ve chosen “Sophia” for myself. I wanted to go through my thought process in choosing this name, both for myself and for others, as I found reading other people’s accounts of choosing their name to be quite helpful in choosing mine.&lt;/p&gt;

&lt;p&gt;My checklist was something like the following (in approximate order of importance):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It had to feel right.&lt;/li&gt;
  &lt;li&gt;It had to feel feminine.&lt;/li&gt;
  &lt;li&gt;None of my close friends have that name.&lt;/li&gt;
  &lt;li&gt;It doesn’t stand out too much.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A common approach would be to feminize my current masculine name. So if my parents had named me Henry at birth, I might use Henrietta. This would have been fine, as I’m not personally bothered by deriving my female name from a male name, but it just doesn’t seem to fit. Another common option is to ask my parents what they would have named me if I had arrived as a girl to them. I &lt;em&gt;think&lt;/em&gt; my mom has told me I would have been “Lindsey” which, for whatever reason, does not feel right. So back to the drawing board.&lt;/p&gt;

&lt;p&gt;Sophia is a name that my wife and I have discussed for years as a potential name for a hypothetical daughter. But since we first started discussing the name, it has become an enormously popular. Rising from around 50th most popular girls name in the 90s, to around 10th in the 00s, to between the 1st and 3rd most popular now. We’ve always wanted to give our children names that fell farther down the list (because of course they will be unique little snowflakes!), so we’re not quite as excited about it as a name for a child now.&lt;/p&gt;

&lt;p&gt;But for me, this could be a good thing. The popularity of the name means that “Sophia” is very recognizably feminine but, because it was more rare when I was young, I know essentially no one who has that name. It thus meets the last three criteria very well. It also has a weird personal connection because I’ve envisioned a daughter with that name—which I’m still not sure if that is good or bad.&lt;/p&gt;

&lt;p&gt;But outside of all of these practical considerations, Sophia has a certain importance to me. To explain, let’s fire up the flashback machine to 2004 or so. At that time in my life I had just begun to play &lt;a href=&quot;https://en.wikipedia.org/wiki/Tabletop_role-playing_game&quot;&gt;tabletop role-playing games&lt;/a&gt; with friends. It’s the kind of thing where you build a character out of the clay of your imagination and a giant rulebook and then roll dice to see what that character is able to do. You do this with friends who have made characters in a similar way, and try to make the voices the characters would make, et cetera. For me, it presented this strange dilemma: I was quite curious about playing a female character but totally apprehensive of doing so in front of the teenage boys  others I played the game with.  [I’d be interested to learn more about how these kinds of games impacted other trans people.]&lt;/p&gt;

&lt;p&gt;Around that time I started playing what would become my favorite video game, The Knights of the Old Republic. It was a game for Xbox that followed the exact same rules as the pen and paper games I played with my friends. But this was single player on the Xbox. For the first time I got to choose the gender of my character, name her, and play her, all to myself. Sure I might have to explain to my brother or friends why my save game had a chick on it but that was so much less daunting than performing as a female in front of teenage boys.&lt;/p&gt;

&lt;p&gt;Anyway, in this game I chose the character who looked most like &lt;em&gt;me&lt;/em&gt;: dark hair, light skin, a woman. I named her Sophia after a character in the book I was reading at the time, Sophie Neveu in The Da Vinci Code. I’ve sort of grown out of The Da Vinci Code, though at the time my Dan Brown obsession was burning hot. And, yes, I realize Sophie’s character in The Da Vinci code is problematic for several reasons, but let’s give 14 year old me a break. The important thing is that it all just felt comfortable. And, props to Bioware, Sophia could do everything that any male character could, including pursuing plot-impacting romances with major female Non-Player-Characters. So adolescent me got to try on the skin of a lesbian jedi who always saved the day. And I fucking loved it.&lt;/p&gt;

&lt;p&gt;For the next decade-plus, Sophia and I (or, I &lt;em&gt;as&lt;/em&gt; Sophia) played &lt;em&gt;so many role playing games&lt;/em&gt;: KOTOR 2, Mass Effect 1-3, Jade Empire, Dragon Age, … the list goes on (and certainly includes non-Bioware games, though those are my favorites). By the time I began to appreciate the fact that I am and have always been trans at age 27, I’ve already been trying on Sophia for nearly half of my life. After looking back and just realizing that fact, there is no way I can “choose” anything else. It doesn’t even feel like choosing at that point. I am Sophia and I have been for longer than even I realized.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Sophia Ray Searcy</name>
          
          
        </author>
      

      

      

      
        <summary type="html">One thing about being trans is that I get to come up with my own name. Plenty of non-trans people do this, sure, but to me it sort of feels like a rite of passage for trans folk. I’ve chosen “Sophia” for myself. I wanted to go through my thought process in choosing this name, both for myself and for others, as I found reading other people’s accounts of choosing their name to be quite helpful in choosing mine. My checklist was something like the following (in approximate order of importance): It had to feel right. It had to feel feminine. None of my close friends have that name. It doesn’t stand out too much. A common approach would be to feminize my current masculine name. So if my parents had named me Henry at birth, I might use Henrietta. This would have been fine, as I’m not personally bothered by deriving my female name from a male name, but it just doesn’t seem to fit. Another common option is to ask my parents what they would have named me if I had arrived as a girl to them. I think my mom has told me I would have been “Lindsey” which, for whatever reason, does not feel right. So back to the drawing board. Sophia is a name that my wife and I have discussed for years as a potential name for a hypothetical daughter. But since we first started discussing the name, it has become an enormously popular. Rising from around 50th most popular girls name in the 90s, to around 10th in the 00s, to between the 1st and 3rd most popular now. We’ve always wanted to give our children names that fell farther down the list (because of course they will be unique little snowflakes!), so we’re not quite as excited about it as a name for a child now. But for me, this could be a good thing. The popularity of the name means that “Sophia” is very recognizably feminine but, because it was more rare when I was young, I know essentially no one who has that name. It thus meets the last three criteria very well. It also has a weird personal connection because I’ve envisioned a daughter with that name—which I’m still not sure if that is good or bad. But outside of all of these practical considerations, Sophia has a certain importance to me. To explain, let’s fire up the flashback machine to 2004 or so. At that time in my life I had just begun to play tabletop role-playing games with friends. It’s the kind of thing where you build a character out of the clay of your imagination and a giant rulebook and then roll dice to see what that character is able to do. You do this with friends who have made characters in a similar way, and try to make the voices the characters would make, et cetera. For me, it presented this strange dilemma: I was quite curious about playing a female character but totally apprehensive of doing so in front of the teenage boys others I played the game with. [I’d be interested to learn more about how these kinds of games impacted other trans people.] Around that time I started playing what would become my favorite video game, The Knights of the Old Republic. It was a game for Xbox that followed the exact same rules as the pen and paper games I played with my friends. But this was single player on the Xbox. For the first time I got to choose the gender of my character, name her, and play her, all to myself. Sure I might have to explain to my brother or friends why my save game had a chick on it but that was so much less daunting than performing as a female in front of teenage boys. Anyway, in this game I chose the character who looked most like me: dark hair, light skin, a woman. I named her Sophia after a character in the book I was reading at the time, Sophie Neveu in The Da Vinci Code. I’ve sort of grown out of The Da Vinci Code, though at the time my Dan Brown obsession was burning hot. And, yes, I realize Sophie’s character in The Da Vinci code is problematic for several reasons, but let’s give 14 year old me a break. The important thing is that it all just felt comfortable. And, props to Bioware, Sophia could do everything that any male character could, including pursuing plot-impacting romances with major female Non-Player-Characters. So adolescent me got to try on the skin of a lesbian jedi who always saved the day. And I fucking loved it. For the next decade-plus, Sophia and I (or, I as Sophia) played so many role playing games: KOTOR 2, Mass Effect 1-3, Jade Empire, Dragon Age, … the list goes on (and certainly includes non-Bioware games, though those are my favorites). By the time I began to appreciate the fact that I am and have always been trans at age 27, I’ve already been trying on Sophia for nearly half of my life. After looking back and just realizing that fact, there is no way I can “choose” anything else. It doesn’t even feel like choosing at that point. I am Sophia and I have been for longer than even I realized.</summary>
      

      
      
    </entry>
  
  
</feed>
