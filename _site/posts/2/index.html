<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    
    
    <title>soph</title>
    <meta name="description" content="Minimal, responsive Jekyll theme for hackers.">
    

    <!-- Configure mathjax according to https://docs.mathjax.org/en/latest/configuration.html#using-plain-javascript -->
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [
                    ['$', '$'],
                    ["\\(", "\\)"]
                ],
                processEscapes: true
            }
        };
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>


    <link rel="stylesheet" href="/assets/soph.css">
    <link rel="stylesheet" href="/assets/main.css">
    <link rel="canonical" href="http://localhost:4000/posts/2/">
    
    
    <link rel="alternate" type="application/rss+xml" title="soph" href="http://localhost:4000/feed.xml">

    

    
    <meta property="og:type" content="article" />
    <meta property="fb:admins" content="123">
    <meta property="og:title" content="soph">
    <meta property="og:site_name" content="soph">
    <meta property="og:url" content="http://localhost:4000/posts/2/">
    <meta property="og:description" content="Minimal, responsive Jekyll theme for hackers.">
    
    <meta property="article:author" content="https://www.facebook.com/defsophiaray">
    
    <meta property="og:image" content="http://soph.info/images/fb_teach.png">
    
    
    <meta name="twitter:card" content="summary_large_image">
    
    <meta name="twitter:site" content="defsophiaray">
    <meta name="twitter:title" content="soph">
    <meta name="twitter:description" content="Minimal, responsive Jekyll theme for hackers.">
    
    <meta name="twitter:creator" content="defsophiaray">
    <meta name="twitter:site" content="defsophiaray">
    
    
    <meta name="twitter:image" content="http://soph.info/images/fb_teach.png">
    

    <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function(d) {
    var wf = d.createElement('script'), s = d.scripts[0];
    wf.src = 'https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js';
    wf.async = true;
    s.parentNode.insertBefore(wf, s);
  })(document);
</script>

    
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-103309791-1', 'auto');
    ga('send', 'pageview');

  </script>


</head>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">soph</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">

  

  

  <ul class="post-list">
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            
              <a class="post-link" href="/2018/02/14/Soph-s-VM-tweaks/">Soph&#39;s VM tweaks</a>
            
          </h1>

          <p class="post-meta">
            Feb 14, 2018
            
            
          </p>
        </header>

        <div class="post-content">
          <h1>What’s this</h1>

<p>(hi, this is a test)</p>

<p>This is a scratch pad for me to use when I set up new virtual machines. I’m sharing it in case anyone else is interested.</p>

<h1>fish is by far my favorite shell</h1>

<p>Install it and configure it following <a href="https://geowarin.github.io/the-missing-fish-shell-tutorial.html">this tutorial</a></p>

<p><code class="highlighter-rouge">omf</code> is a handy package manager for fish. You can install <a href="https://github.com/oh-my-fish/oh-my-fish/blob/master/docs/Themes.md#sushi">themes</a> with it and my fav is probably <code class="highlighter-rouge">sushi</code>.</p>

<p>If you’re using anaconda, you’ll have to remember to use <code class="highlighter-rouge">activate</code> instead of <code class="highlighter-rouge">source activate</code> <a href="https://github.com/conda/conda/issues/2611#issuecomment-230894534">details</a>.</p>

<h1>tmux</h1>

<p>I love tmux! I p much always install it first thing. To make it more useful, I add options by creating the following file at <code class="highlighter-rouge">~/.tmux.conf</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>set-option -g mouse on
set-option -g default-command /usr/bin/fish
</code></pre></div></div>

<h1>other tools</h1>

<ul>
  <li>install <a href="https://github.com/moonpyk/dtrx">dtrx</a> for common sense file extraction
    <ul>
      <li><code class="highlighter-rouge">sudo apt install dtrx</code></li>
    </ul>
  </li>
  <li><a href="http://glances.readthedocs.io/en/stable/index.html">glances</a></li>
  <li><a href="https://github.com/wookayin/gpustat">gpustat</a></li>
</ul>

<h1>Access Jupyter from your server</h1>

<p>I typically set up a jupyter server mostly according to Chris Albon’s instructions <a href="https://chrisalbon.com/software_engineering/cloud_computing/run_project_jupyter_on_amazon_ec2/">here</a>.</p>

<h1>Start Jupyter on restart</h1>

<p>Previously, my workflow was something like this: go to console in browser and start ec2, go to terminal and mosh into ec2, start jupyter notebook, go back to
browser and use jupyter. That’s an annoying amount of steps. I like to simplify this so that on every device restart, my machine automagically starts a jupyter notebook server and glances (which I use to monitor the machine’s resource usage).</p>

<p>Here’s the solution I found, which is a modification of <a href="http://rodriguezandres.github.io/2017/01/18/jupyter-aws/">this</a>. Modify your <code class="highlighter-rouge">/etc/rc.local</code> to include the following above the <code class="highlighter-rouge">exit 0</code> line:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$PATH</span><span class="s2">:/home/ubuntu/miniconda3/bin"</span>
nohup jupyter notebook <span class="nt">--notebook-dir</span><span class="o">=</span>/home/ubuntu/ &amp;
nohup glances <span class="nt">-w</span> &amp;

<span class="nb">exit </span>0
</code></pre></div></div>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            
              <a class="post-link" href="/2018/02/01/Paperspace-how-to-cheap-cloud-GPU/">Paperspace how-to (cheap cloud GPU)</a>
            
          </h1>

          <p class="post-meta">
            Feb 1, 2018
            
              

 •
  
    
    
  


            
            
          </p>
        </header>

        <div class="post-content">
          <p>The use of GPUs have become quite important for applications of Deep Learning. The landscape of this hardware has lately become quite interesting. The <a href="https://arstechnica.com/tech-policy/2018/01/cryptocurrency-boom-creates-insane-global-graphics-card-shortage/">cryptocurrency fad</a> has led to GPUs becoming expensive and/or unavailable. One solution to this problem is to rent a computer with a GPU from Google, Amazon, Microsoft, and others. Google even <a href="https://cloudplatform.googleblog.com/2017/11/new-lower-prices-for-GPUs-and-preemptible-Local-SSDs.html">recently lowered</a> their GPU prices quite substantially. I’ll save doing a full comparison of each platform for later, but what I’ll go over today is getting started with a relatively new service, <a href="https://techcrunch.com/2017/05/03/paperspace-launches-gpu-powered-virtual-machines-loaded-with-tools-for-data-scientists/">PaperSpace</a> based in my home of Brooklyn &lt;3.</p>

<p>The virtue of paperspace is that their entry-level GPU offering costs $0.40/hr (compared to Google’s new $0.45/hr and Amazon’s $0.90/hr) but <a href="https://medium.com/initialized-capital/benchmarking-tensorflow-performance-and-cost-across-different-gpu-options-69bd85fe5d58">benchmarks ahead</a> of Amazon and other offers based on the Tesla K80.</p>

<p>Below, I’ll show you how to get up and running quickly and how to set up cost-saving measures, like auto-shutdown.</p>

<h1>Steps to get running</h1>

<p>First, as with any new machine, update the current packages with</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt update
sudo apt upgrade
</code></pre></div></div>

<p>(Note: I had to add the <code class="highlighter-rouge">--fix-missing</code> flag to <code class="highlighter-rouge">sudo apt update</code>)</p>

<p>Add a new user according to <a href="https://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-ubuntu-quickstart">these instructions</a>.</p>

<h2>open ports with ufw</h2>

<p>By default, Paperspace has a very strict firewall (this is a good thing). We’re going to want to get to our jupyter notebooks, though, so we need to open up some ports. You can do that with <a href="https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server">these instructions</a>.</p>

<p>My version is pretty unsafe (it allows access from any IP) so feel free to check that link for info on restricting the IP that can access your jupyter port.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo ufw allow 8888
sudo ufw allow 60000:61000/udp
</code></pre></div></div>

<h1>set up jupyter</h1>

<h1>fix autoshutdown with ssh</h1>

<p>https://paperspace.zendesk.com/hc/en-us/articles/115002807447-How-do-I-use-Auto-Shutdown-on-my-Linux-machine-when-connecting-through-SSH-</p>

<h1>set up ssh keys</h1>

<p>https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys–2</p>

<p>https://apple.stackexchange.com/questions/48502/how-can-i-permanently-add-my-ssh-private-key-to-keychain-so-it-is-automatically</p>

<h1>Install cuda 9.1</h1>

<p>You can use the <a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/">official guide</a> but I prefer <a href="https://askubuntu.com/questions/967332/how-can-i-install-cuda-9-on-ubuntu-17-10">these instructions</a>.</p>

<h1>Install cudnn</h1>

<p>http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html</p>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            
              <a class="post-link" href="/2017/12/04/Deep-Learning-Tips/">Deep Learning Tips</a>
            
          </h1>

          <p class="post-meta">
            Dec 4, 2017
            
            
          </p>
        </header>

        <div class="post-content">
          <p>I often find myself in roughly this situation:</p>

<blockquote>
  <p>I’ve done a lot of work to pre-process data, researched different DL architectures and selected one (or more), modified it so that it works well on my data.
And now I’ve got a model that does well, but not quite as well as I want it to.</p>
</blockquote>

<p>Below I’ll outline steps that I find very useful in this situation. Of course, more detail about how to get to that point is for another post. Also, I’m using Keras so many of these are specific to that tool, but they could absolutely be applied to other DL packages.</p>

<h2>Clean up training code and improve logging.</h2>

<p>My typical workflow when I’m building or tweaking a model by hand is to run Kears in a Jupyter notebook. This works fine if the entire pipeline runs in a few minutes but doesn’t work if I need to close my laptop while the pipeline is running. Jupyter often has trouble gracefully reconnecting and then I lose all the <code class="highlighter-rouge">verbose</code> info.</p>

<p>Porting my code into a self-contained python script allows me to connect to a machine over mosh and tmux, run the script, and then forget about it. This is handy on it’s own but it’ll be extremely handy when we get to the later tips.</p>

<p>The tools I use for this are:</p>

<ul>
  <li><a href="https://keras.io/callbacks/#csvlogger"><code class="highlighter-rouge">keras.callbacks.CSVLogger(...)</code></a></li>
  <li><a href="https://keras.io/callbacks/#tensorboard"><code class="highlighter-rouge">keras.callbacks.TensorBoard(...)</code></a></li>
  <li><a href="https://keras.io/callbacks/#modelcheckpoint"><code class="highlighter-rouge">keras.callbacks.ModelCheckpoint(..., save_best_only=True)</code></a></li>
</ul>

<p><code class="highlighter-rouge">CSVLogger</code> takes the output from verbose and stores it in a csv file for later. If you’re using tmux, it should be preserving your terminal log (and the <code class="highlighter-rouge">verbose</code> output) but csv puts all of that history data in a format where you can easily use it.</p>

<p><code class="highlighter-rouge">TensorBoard</code> is super handy if you want to be able to monitor the progress of a long-running model from somewhere other than your terminal. I can access this from my iPad and it looks great!
<img src="/images/tips/tb.png" alt="" /></p>

<p><code class="highlighter-rouge">ModelCheckpoint</code> saves your model every so often (you set the frequency as a parameter). This is nice on its own because it allows you to access a model that was trained in a script from anywhere (including my preferred tinkering environment, Jupyter). Even more than that, if you use <code class="highlighter-rouge">save_best_only=True</code>, then the script is automatically saving space by only saving the best performing model (you should youse <code class="highlighter-rouge">val_loss</code> or some other validation metric with this option).</p>

<h2>Learning Rate Schedule</h2>

<ul>
  <li><a href="https://keras.io/callbacks/#learningratescheduler"><code class="highlighter-rouge">keras.callbacks.LearningRateScheduler</code></a></li>
  <li><a href="https://keras.io/callbacks/#reducelronplateau"><code class="highlighter-rouge">keras.callbacks.ReduceLROnPlateau</code></a> This is my preference. I use this in conjunction with EarlyStopping and ModelCheckpoint all the time.</li>
</ul>

<h2>Use noise and other transformations to enlarge your datasets</h2>

<ul>
  <li><a href="https://keras.io/preprocessing/image/#imagedatagenerator">keras.preprocessing.image.ImageDataGenerator()</a></li>
  <li><a href="https://www.tensorflow.org/versions/master/tutorials/audio_recognition#background_noise">Tensorflow blog discussing this with background noise</a></li>
</ul>

<h2>Optimize</h2>

<p>There are many hyperparameters that can be optimized:</p>
<ul>
  <li>Learning rate</li>
  <li>Dropout rate</li>
  <li>Preprocessing steps</li>
  <li>Different architectures (size and shape of layers as well as count) and parameters</li>
  <li>Regularizers and parameters</li>
  <li>Initializers and parameters</li>
  <li>and more!</li>
</ul>

<p>These create an enormous space of possible models for which to test. My recommendation is to find something that works and then from that functioning model determine plausible options for the above hyperparameters. Then throw what you have into hyperopt.</p>

<ul>
  <li><a href="https://github.com/hyperopt/hyperopt">HyperOpt does this automatically</a>. It’s poorly documented but fairly easy to use.</li>
</ul>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            
              <a class="post-link" href="/2017/10/18/scratch/">Deep learning from scratch with python</a>
            
          </h1>

          <p class="post-meta">
            Oct 18, 2017
            
              

 •
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  


            
            
          </p>
        </header>

        <div class="post-content">
          <p>Last week I presented at the <a href="https://web.archive.org/web/20171018141234/https://www.meetup.com/NYC-Data-Science-Study-Group/events/243747107/">Data Science Study Group</a> on a project of mine where I built a deep learning platform from scratch in python.</p>

<p>For reference, here’s my <a href="https://github.com/sophiaray/sophscratch">code</a> and <a href="http://soph.info/scratch.pdf">slides</a>.</p>

<p>First, my project drew primarily from two sets of sources, without which I never would have completed this project. First, there are many examples of folks doing this online. Here’s an incomplete list in python:</p>

<ul>
  <li>** <a href="http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/">Deep Learning From Scratch I-V</a> by <a href="https://twitter.com/deepideas_net">Daniel Sabinasz</a> **</li>
  <li><a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/">Implementing a Neural Network from Scratch in Python – An Introduction</a> by <a href="https://twitter.com/dennybritz">Denny Britz</a></li>
  <li><a href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/">Understanding and coding Neural Networks From Scratch in Python and R</a> by <a href="https://twitter.com/sunil2ray?lang=en">Sunil Ray</a></li>
  <li><a href="https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/">How to Implement the Backpropagation Algorithm From Scratch In Python</a></li>
</ul>

<p>While all of these are useful, Sabinasz’s was what I based my project on because he implements a system that builds a computational graph and includes a true backpropogation algorithm. The others I saw do this implicitly by calculating the gradients operation-by-operation. That approach is fine for a single demo but I wanted something that mimicked the flexibility of tensorflow, allowing me to compare different network structures and activations without starting over each time.</p>

<p>In addition to these resources, I drew heavily from <a href="http://www.deeplearningbook.org/">Deep Learning</a> by Goodfellow, Bengio, and Courville. I’m certain that the other examples I looked toward used this book as well.</p>

<p>While I started with Sabinasz’s code, I made a few modifications and improvements including:</p>

<ul>
  <li>Add graph visualization with <a href="http://graphviz.readthedocs.io/en/stable/manual.html">python Graphviz</a></li>
  <li>Remove the use of globals for the computational graph</li>
  <li>Simplify backprop algorithm by adding gradient calculations to the operation classes</li>
  <li>Add a Relu activation function</li>
  <li>Tweak the visualizations</li>
</ul>

<p>Here’s the learning rate plotted along with the classification boundary for a relu network with 4 hidden nodes.
<img src="/images/relu-w-hidden-nodes.png" alt="" /></p>

<p>And here’s the computational graph. You can really see the benefit of tracking the graph and automating the backprop algorithm for a graph of this size.
<img src="/images/relu-graph.png" alt="" /></p>

<h2>What I still want to do</h2>

<ol>
  <li>I want to write up a blog summarizing my talk and the process for creating this. I think it could be a very useful explanatory tool.</li>
  <li>I have a strong feeling that some of the gradients in here are inaccurate.
    <ul>
      <li>In many cases the network fails to learn for any learning rate schedule unless I give it a much higher capacity than it needs (e.g. 4+ hidden nodes in the XOR task).</li>
      <li>In simple cases, like separable data, the model should be able to get arbitrarily close to $J=0$ but fails to do so.</li>
      <li>The softmax gradient seems to differ from that found in other sources</li>
    </ul>
  </li>
  <li>I want to extend this model to larger datasets and deeper networks. Right now it runs into what I think are underflow errors in these cases but they should be possible to avoid.</li>
</ol>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            
              <a class="post-link" href="/2017/07/26/Documents/">Trans fam, update your documents!</a>
            
          </h1>

          <p class="post-meta">
            Jul 26, 2017
            
            
          </p>
        </header>

        <div class="post-content">
          <p>Trans friends, here’s a periodic reminder that it might be useful to update your documents (name, gender marker, id). I’ve recently done this. Here’s the quickest and cheapest path for US citizens:</p>

<p>1 <strong>Update your passport gender marker.</strong> For this you need proof of citizenship (like a birth certificate), a letter from your doctor, and a new passport photo. Use the template in the link below. The cost is $110 and this can be done in one or two days. <a href="https://travel.state.gov/content/passports/en/passports/information/gender.html">info here</a>
2 <strong>Update your name in court.</strong> This process differs state by state. Roughly, you’ll schedule a hearing, gather documents including a birth certificate, publish an announcement in the paper (trans folks are generally able to waive the publication requirement in NY), then get certified copies of the court order <a href="https://srlp.org/resources/namechange/">NYC</a>, <a href="http://www.nycourts.gov/CourtHelp/DIY/nameChange.shtml">NY</a>, <a href="https://slwordpress.rutgers.edu/socialjustice/wp-content/uploads/sites/51/2016/08/NJ-Name-Gender-Change-Guide-for-Residents-v1-1.pdf">NJ</a>
3 <strong>Update your passport name.</strong> Do this within a year of step one and it’s free and only requires the court order (<a href="https://eforms.state.gov/Forms/ds5504.pdf">form here</a>).
4 Everything else (except sometimes a birth certificate) can be done with an updated passport and possibly some additional documentation.</p>

<p>If you need help, I’d love to or help find someone who can. If money is a problem, <a href="https://www.transassistance.org">Trans Assistance Project</a>, <a href="http://tldef.org">TLDEF</a>, <a href="https://srlp.org">SRLP</a>, and other places have provided that in the past. Let me know if you have any trouble.</p>

        </div>
        
      </li>
    
  </ul>

  
  <div class="pagination">
    
      <a class="previous" href="/posts/3/">&laquo; Older</a>
    

    
      <a class="next" href="/">Newer &raquo;</a>
    
  </div>



</div>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy; Sophia Ray Searcy - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://localhost:4000/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
